{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bf0c803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport pandas as pd\\nimport torch\\nfrom transformers import BertTokenizer, BertForSequenceClassification\\n\\n# Load CSV file\\ncsv_file_path = \"bursa_news_articles.csv\"\\ndata = pd.read_csv(csv_file_path)\\n\\n# Ensure \\'Date\\' column is in datetime format\\ndata[\\'Date\\'] = pd.to_datetime(data[\\'Date\\'])\\n\\n# Sort the DataFrame based on the \\'Date\\' column in ascending order\\ndata.sort_values(by=\\'Date\\', inplace=True)\\n\\n# Load the fine-tuned BERT model and tokenizer\\nmodel_path = \"bert_sentiment_model\"  # Replace with the path to your fine-tuned BERT model\\ntokenizer_path = \"bert_tokenizer\"  # Replace with the path to your BERT tokenizer\\ntokenizer = BertTokenizer.from_pretrained(tokenizer_path)\\nmodel = BertForSequenceClassification.from_pretrained(model_path)\\n\\n# Function to classify sentiment\\ndef classify_sentiment(title):\\n    input_ids = tokenizer.encode(title, add_special_tokens=True, max_length=512, truncation=True, padding=\\'max_length\\', return_tensors=\\'pt\\')\\n    with torch.no_grad():\\n        outputs = model(input_ids)\\n    logits = outputs.logits\\n    probabilities = torch.softmax(logits, dim=1).squeeze().tolist()\\n    \\n    # Assuming your model has 3 classes (Positive, Negative, Neutral)\\n    sentiment_classes = [\\'Positive\\', \\'Negative\\', \\'Neutral\\']\\n    predicted_class_index = probabilities.index(max(probabilities))\\n    return sentiment_classes[predicted_class_index]\\n\\n# Apply sentiment analysis to each title\\ndata[\\'Sentiment\\'] = data[\\'Title\\'].apply(classify_sentiment)\\n\\n# Save the results to a new CSV file\\noutput_csv_file = \"classified_titles.csv\"\\ndata.to_csv(output_csv_file, index=False)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Load CSV file\n",
    "csv_file_path = \"bursa_news_articles.csv\"\n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Ensure 'Date' column is in datetime format\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "# Sort the DataFrame based on the 'Date' column in ascending order\n",
    "data.sort_values(by='Date', inplace=True)\n",
    "\n",
    "# Load the fine-tuned BERT model and tokenizer\n",
    "model_path = \"bert_sentiment_model\"  # Replace with the path to your fine-tuned BERT model\n",
    "tokenizer_path = \"bert_tokenizer\"  # Replace with the path to your BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(tokenizer_path)\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Function to classify sentiment\n",
    "def classify_sentiment(title):\n",
    "    input_ids = tokenizer.encode(title, add_special_tokens=True, max_length=512, truncation=True, padding='max_length', return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "    logits = outputs.logits\n",
    "    probabilities = torch.softmax(logits, dim=1).squeeze().tolist()\n",
    "    \n",
    "    # Assuming your model has 3 classes (Positive, Negative, Neutral)\n",
    "    sentiment_classes = ['Positive', 'Negative', 'Neutral']\n",
    "    predicted_class_index = probabilities.index(max(probabilities))\n",
    "    return sentiment_classes[predicted_class_index]\n",
    "\n",
    "# Apply sentiment analysis to each title\n",
    "data['Sentiment'] = data['Title'].apply(classify_sentiment)\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "output_csv_file = \"classified_titles.csv\"\n",
    "data.to_csv(output_csv_file, index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e3269b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\irwin\\AppData\\Roaming\\Python\\Python310\\site-packages\\spacy\\util.py:837: UserWarning: [W095] Model 'en_core_web_sm' (3.5.0) was trained with spaCy v3.5 and may not be 100% compatible with the current version (3.3.3). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\irwin\\AppData\\Local\\Temp\\ipykernel_25472\\1581677755.py:15: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  data['Date'] = pd.to_datetime(data['Date'])\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Load spaCy for text preprocessing\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Load CSV file\n",
    "csv_file_path = \"bursa_news_articles.csv\"\n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Ensure 'Date' column is in datetime format\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "# Sort the DataFrame based on the 'Date' column in ascending order\n",
    "data.sort_values(by='Date', inplace=True)\n",
    "\n",
    "# Load the fine-tuned BERT model and tokenizer\n",
    "model_path = \"bert_sentiment_model\"  # Replace with the path to your fine-tuned BERT model\n",
    "tokenizer_path = \"bert_tokenizer\"  # Replace with the path to your BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(tokenizer_path)\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Define a function for text normalization with negation handling and stopwords removal\n",
    "def normalise_with_negation(msg):\n",
    "    doc = nlp(msg)\n",
    "    res = []\n",
    "    negate = False\n",
    "\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct or token.is_space or not(token.is_oov):\n",
    "            pass\n",
    "        else:\n",
    "            if token.text == \"not\" and not negate:\n",
    "                negate = True\n",
    "            elif negate:\n",
    "                res.append(\"not_\" + token.lemma_.lower())\n",
    "                negate = False\n",
    "            else:\n",
    "                # Remove stopwords\n",
    "                if token.lemma_.lower() not in stopwords.words('english'):\n",
    "                    res.append(token.lemma_.lower())\n",
    "\n",
    "    return res\n",
    "\n",
    "# Function to preprocess and classify sentiment\n",
    "def classify_sentiment(title):\n",
    "    # Preprocess the title using normalise_with_negation\n",
    "    preprocessed_title = normalise_with_negation(title)\n",
    "    \n",
    "    input_ids = tokenizer.encode(preprocessed_title, add_special_tokens=True, max_length=512, truncation=True, padding='max_length', return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "    logits = outputs.logits\n",
    "    probabilities = torch.softmax(logits, dim=1).squeeze().tolist()\n",
    "    \n",
    "    # Assuming your model has 3 classes (Positive, Negative, Neutral)\n",
    "    sentiment_classes = ['Positive', 'Negative', 'Neutral']\n",
    "    predicted_class_index = probabilities.index(max(probabilities))\n",
    "    return sentiment_classes[predicted_class_index]\n",
    "\n",
    "# Apply sentiment analysis to each title without storing preprocessed titles in the data\n",
    "data['Sentiment'] = data['Title'].apply(classify_sentiment)\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "output_csv_file = \"classified_titles.csv\"\n",
    "data.to_csv(output_csv_file, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e1",
   "language": "python",
   "name": "e1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
